# Команда QBt (кубит) - выявление инноваций

### Идея
Ввиду странного изначального датасета было придумано две ветки развития:
* Выделение особенностей продукта в анкете на включение в реестр инновационных предложений
	* Возможность анализа свежедобавленного описания
	* Подход: поиск ключевых слов в тексте -> восстановление словосочетаний по контексту -> фильтрация избыточных и нерелеватных выражений за счёт реестра существуюзей продукции
* Ранжирование продукции внутри категории по "интересности" с точки зрения инновационности/необычности
	* Статистическая модель
	* Учитывает важность атрибутов
	* Учитывает заполненность описания
	* Учитывает необычность описания

### План работ:

###### Ветка по оценки таблицы атрибутов

- [x] Инструменты для анализа и преобразвоания исходных данных
- [x] Анализ перечня продуктов и атрибутов, модель ранжированная по инновационности / интересности
- [x] Обсчитывание весов внутри категорий для каждого продукта 
- [x] Фильтр частых атрибутов
- [ ] Умное проставление весов, учитывать тип информации
	- [ ] Числа от большого к меньшему
	- [ ] Текст - расстояние между словами
	- [ ] Размер - объём
	- [ ] Нормализация величин
- [ ] Выделение ключевых слов в таблице по категори
	- [ ] Выделение ключевых слов
	- [ ] *Возможно* градиентный спуск
	- [ ] *Возможно* восстановление контекста слов w2v
- [ ] Визуализировать таблицу с весами `30%/100%`
	- [ ] Продукты в категории
	- [ ] Отображение ключевых атрибутов
	- [ ] Отсортированный список продуктов
	- [ ] Выделение причин победы того или иного продукта
	- [ ] Отображение ключевых слов
- [ ] Интерфейс добавления новго продукта в категорию и его анализ

###### Ветка анализа анкет с текстовым описанием заявок на инновационный продукт

- [x] Анализ описаний инновационных продуктов
- [x] Минимальный алгоритм выделения ключевых слов, поиска особенностей продукта в описании
- [ ] Интерфейс описания инновационного продукта
	- [ ] Визуализация выделения кусков текста в тексте
	- [ ] Отображения рекомендаций по инновационности
- [ ] Интерфейс добавления текстового описания инновационного продукта
- [ ] Выделение ключевых характеристик из текста, опираясь на списки атрибутов в общей таблице продуктов
- [ ] Переработать алгоритм выделения ключевых фраз
	- [x] TF-IDF сравнение bag of words/ngramms/tf-idf
	- [ ] Обучить свою модель W2V на существующем тексте
	- [ ] Восстанавливать конктест
	- [ ] *Опробовать* logistic regression/random forest
	- [ ] Фильтровать выделенные ключевые слова с помощью базы обычной продукции
	- [ ] Фразы с восстановленным контекстом с помощью w2v, не найденные в исследуемом  тексте использовать для выведения рекомендаций
	- [ ] Другие рекомендации

###### [Посмотреть на работу алгоритма](https://cloud.mail.ru/public/3eEu/5Y4v7FNfB)

###### [Папка с предобработанными данными](https://www.dropbox.com/sh/h50jpmp1k7x8tqi/AABtsn3-Jm66aRvT53dIM4N1a?dl=0)

### Команда
![Image alt](./commando.gif)

### Структура файлов и описание

`analyseUtils/`		

Файл	|	Смысл
----------------------	|	----------------------
`getCategoryTable.py`	|	Генерирует одну таблицу с листами на каждую категорию и полным списком продуктов по категории
`getCategoryTables.py`	|	Генеририет таблицы на каждую категорию, в каждой из которых построчно отображается описание продуктов
`prepareData.py`	|	Считывает данные из исходных таблиц первого датасета, преобразуем в сжатый и удобный формат, пишет в бинарник, для быстрого восстановления

`data/`		

Файл	|	Смысл
----------------------	|	----------------------
`data.bin`	|	База данных первого датасета в бинарном формате
`inn.xlsx, cat.xlsx, att.xlsx, prod2.csv, prod.csv`	|	Исходные файлы датасета

`dataBase/`	

Файл	|	Смысл
----------------------	|	----------------------
`categoryTable.py`	|	Создаёт объект, который производит аналитику по категории, выдаёт ранжированный список продуктов, хранит веса, генерирует матрицу для вывода информации, а также выводит данные в эксель таблицы по категориям
`dataBase.bin`	|	База данных второго датасета, содержащая объект данных по категориям
`workWithDatabase.py`	|	Считывает второй датасет и преобразует класс, содержащий описание продуктов по категориям. Кроме того, выполняет предварительные рассчёты весов и некоторых характеристик. Пишет и считывает себя из бинарного файла.
`структура.txt`	|	Подсказка для нашего специалиста по связям с общественностью, который обещал сделать интерфейс

`keyPhrases/`		

Файл	|	Смысл
----------------------	|	----------------------
`normalizeWords.py`	|	Нормализует слова
`restab.xlsx`	|	Пример нахождения в анкете важных характеристик продукта
`stopWordsFilter.py`	|	Фильтр стоп-слов
`weightSearch.py`	|	Анализирует анкеты из таблицы и создаёт таблицу с найденными важными характеристиками
`freqAnlz.py`	|	Выделяет в тексте анкет ключевые слова. 

`probAndFreqTable/`		

Файл	|	Смысл
----------------------	|	----------------------
`tableStat.py`	|	Анализирует перечень продуктов в категории и выдаёт в эксель
		
`resultData/`	-	Пример работы выделения инновационных продуктов по аттрибутам


### Методология

Выделение выражений:
* Удаляем стоп-слова и символы
* Нормализуем
* Ищем веса слов tf-idf
* Для каждого восстанавливаем контекст регрессионной моделью
* Приводим выражение к тому виду, что были в исходном тексте с помощью word2vec

Ранжирование по "интересности":
* Считаем частоту использования каждого атрибута по категориям 
* За вес "встречаемости" берем число атрибутов / частота атрибута
* Внутри категории по каждому атрибуту считаем число значений
* Вес "заполненности" = число продуктов / число атрибутов 
* Считаем частоту использования каждого значения в каждом атрибуте
* Вес значения = число заполненных ячеек по атрибуту / частоту использования (идея, что такие ячейки могут сообщить больше интересной информации, далее надо будет убирать шум/мусор)
* Нормализуем веса для атрибутов
* Считаем вес по продукту суммой веса значения * ("встречаемость" + "заполненность") атрибута
* Ранжируем, выводим